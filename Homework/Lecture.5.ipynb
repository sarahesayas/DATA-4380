{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8588b4b3",
   "metadata": {},
   "source": [
    "# Unix Shell\n",
    "\n",
    "There is a lot that can be done on the Unix shell command prompt. For homework, we will do some useful manipulations of CSV files.\n",
    "\n",
    "There is plenty of material online that will help you figure out how to do various tasks on the command line. Some example resources I found by googling:\n",
    "\n",
    "* Paths and Wildcards: https://www.warp.dev/terminus/linux-wildcards\n",
    "* General introduction to shell: https://github-pages.ucl.ac.uk/RCPSTrainingMaterials/HPCandHTCusingLegion/2_intro_to_shell.html\n",
    "* Manual pages: https://www.geeksforgeeks.org/linux-man-page-entries-different-types/?ref=ml_lbp\n",
    "* Chaining commands: https://www.geeksforgeeks.org/chaining-commands-in-linux/?ref=ml_lbp\n",
    "* Piping: https://www.geeksforgeeks.org/piping-in-unix-or-linux/\n",
    "* Using sed: https://www.geeksforgeeks.org/sed-command-linux-set-2/?ref=ml_lbp\n",
    "* Various Unix commands: https://www.geeksforgeeks.org/linux-commands/?ref=lbp\n",
    "* Cheat sheets:\n",
    "    * https://www.stationx.net/unix-commands-cheat-sheet/\n",
    "    * https://cheatography.com/davechild/cheat-sheets/linux-command-line/\n",
    "    * https://www.theknowledgeacademy.com/blog/unix-commands-cheat-sheet/\n",
    "    \n",
    "These aren't necessarily the best resources. Feel free to search for better ones. Also, don't forget that Unix has built-in manual pages for all of its commands. Just type `man <command>` at the command prompt. Use the space-bar to scroll through the documentation and \"q\" to exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacff67-3afe-40d6-bf65-4a262fdd8636",
   "metadata": {},
   "source": [
    "1. After unziping the Kaggle CSV files, make a new directory for the original zip files, and move the files there. In case you accidentally mess up one of the CSV files, you'll be able unzip the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed92587-33ce-4954-8adb-a1701201a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir Zip-Files.csv\n",
    "cd  Zip-Files.csv\n",
    "\n",
    "kaggle datasets download -d henryshan/starbucks\n",
    "kaggle datasets download -d vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "kaggle datasets download -d yasserh/titanic-dataset\n",
    "kaggle datasets download -d rishidamarla/heart-disease-prediction\n",
    "kaggle datasets download -d ananthr1/weather-prediction\n",
    "kaggle datasets download -d harishkumardatalab/housing-price-prediction\n",
    "kaggle datasets download -d muhammadbinimran/housing-price-prediction-data\n",
    "kaggle datasets download -d rafsunahmad/world-all-university-ranking-factors\n",
    "kaggle datasets download -d ayaz11/used-car-price-prediction\n",
    "kaggle datasets download -d iammustafatz/diabetes-prediction-dataset\n",
    "kaggle datasets download -d thedevastator/cancer-patients-and-air-pollution-a-new-link\n",
    "kaggle datasets download -d imtkaggleteam/breast-cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71857ea-e49d-4192-b810-563d057a3bde",
   "metadata": {},
   "source": [
    "2. The \"diabetes_prediction_dataset.csv\" file has a lot of entries. Create 3 new CSV files, each with about 1/3 of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e4c3e-2cb9-4d80-86e7-d058af1b01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the first line of the file into the new files\n",
    "head -1 diabetes_prediction_dataset.csv >> DIABETES2.csv\n",
    "head -1 diabetes_prediction_dataset.csv >> DIABETES3.csv\n",
    "\n",
    "# Put first 3335 of file into first diabetes file\n",
    "head -n 3335 diabetes_prediction_dataset.csv >> DIABETES1.csv\n",
    "\n",
    "# Put lines 3336-6668 into second diabetes file\n",
    "head -n 6668 diabetes_prediction_dataset.csv | tail -n +3336 >> DIABETES2.csv\n",
    "\n",
    "# Put lines 6669-10,001 into third diabetes file\n",
    "head -n 10001 diabetes_prediction_dataset.csv | tail -n +6669 >> DIABETES3.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e7c1f-1086-427a-9d77-3e51ababdb85",
   "metadata": {},
   "source": [
    "3. Create 2 new CSV files from Heart_Disease_Prediction.csv, one containing rows with \"Presence\" label and another with \"Absence\" label. Make sure that the first line of each file contains the field names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773214d-1388-49f8-ad71-78ea8855ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 files with the head line of OG .csv\n",
    "head -n 1 Heart_Disease_Prediction.csv > heart-presence-file.csv\n",
    "head -n 1 Heart_Disease_Prediction.csv > heart-absence-file.csv\n",
    "\n",
    "# Select lines with \"Presence\" and put in to Presence File\n",
    "grep \"Presence\" Heart_Disease_Prediction.csv >> heart-presence-file.csv\n",
    "\n",
    "# Select lines with \"Absence\" and put in to Absence File\n",
    "grep \"Absence\" Heart_Disease_Prediction.csv >> heart-absence-file.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c02eec-ad03-4f24-995b-12df69101514",
   "metadata": {},
   "source": [
    "4. What fraction of cars in car_web_scraped_dataset.csv have had no accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da5339-b776-4587-94d3-4989fbdb4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the word count of grep \"No accidents\"\n",
    "grep \"No accidents\" car_web_scraped_dataset.csv | wc -l\n",
    "# -> 2223\n",
    "\n",
    "# Take the word count of everything\n",
    "wc -l car_web_scraped_dataset.csv\n",
    "# ->  2841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f71ce72-5542-423e-b6db-0ae2a8970894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7824709609292503"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2223/2841"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf685a3f-a11d-4b6e-b7d2-098b1eb91e1b",
   "metadata": {},
   "source": [
    "5. Make the following replacements in Housing.csv, output the result into a new CSV:\n",
    "- yes -> 1\r\n",
    "- no -> 0\r\n",
    "- unfurnished -> 0\r\n",
    "- furnished -> 1\r\n",
    "- semi-furnished -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2bd3d-d863-4dac-afcf-da75eb66a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one line, make the replacements\n",
    "sed 's/yes/1/g; s/no/0/g; s/unfurnished/0/g; s/,furnished/,1/g; s/semi-furnished/2/g' Housing.csv > New-Housing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0917c60-c68f-4f07-a0b5-23d926a4d00d",
   "metadata": {},
   "source": [
    "- s/ tells sed to substitute every occurrence of the pattern (”yes” or “no” or “unfurnished”, etc.)\r\n",
    "- /g at the end stands for “global” and makes sure all occurrences of the pattern on EACH LINE are replaced, not just the first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042f50f-5e97-41a6-9e4d-8bb10d71a763",
   "metadata": {},
   "source": [
    "6. Create a new CSV files from Mall_Customers, removing \"CustomerID\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168be40-028d-45c4-9ec0-92c0ce613924",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut -d ',' -f 2- Mall_Customers.csv > New_Mall_Customers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ebc304-7edc-4c0d-a096-08c0f9aed808",
   "metadata": {},
   "source": [
    "- cut -d ‘,’ makes the separator a comma\r\n",
    "- -f 2- says we want to keep columns starting from the second column onwards ⇒ removing “CustomerID”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580ebda-fa0b-4452-b1fa-83c29820b1bf",
   "metadata": {},
   "source": [
    "7. `world all university rank and rank score.csv’, Create a new file that contains the sum of the following fields for each row:\r\n",
    "    \r\n",
    "    Research Quality Score\r\n",
    "    \r\n",
    "    Industry Score\r\n",
    "    \r\n",
    "    International Outlook\r\n",
    "    \r\n",
    "    Research Environment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40939a2d-d87e-45d3-afff-b26891d0d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install bc\n",
    "sudo apt install bc\n",
    "\n",
    "#Then take the columns\n",
    "cut -f 5,6,7,8 -d ',' 'world all university rank and rank score.csv' | tr -s ',' '+' | bc > Summed-Rank-Scores.csv\n",
    "\n",
    "#I kept getting 'illegal characters' and 'syntax' errors\n",
    "\n",
    "# This also did not work\n",
    "cut -f 5,6,7,8 -d ',' world\\ all\\ university\\ rank\\ and\\ rank\\ score.csv | tr -s ',' '+' | bc > Summed-Rank-Scores.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe9011-01d6-4b9b-91b8-f1bcda9a52cd",
   "metadata": {},
   "source": [
    "- cut -d ‘,’ makes the separator a comma\r\n",
    "- -f 5,6,7,8 will focus on the 5th-8th columns in each row (which includes the Research Quality Score, Industry Score, International Outlook, and Research Environment Score columns\r\n",
    "- tr ‘,’ ‘+’ will replace the comma between the 5th-8th columns to plus signs for summing\r\n",
    "- bc will calculate the +"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a1b4a-2784-4afe-9b16-3c8ca6176d06",
   "metadata": {},
   "source": [
    "8. Sort the \"cancer patient data sets.csv\" file by age. Make sure the output is a readable CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073ee4e-9e6a-4fde-8624-30755b5512a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort -t ',' -k 3 -n 'cancer patient data sets.csv' > sorted_cancer_patient_data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
